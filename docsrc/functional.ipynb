{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Introduction to Functional Parsing in Python\n",
    "============================================\n",
    "\n",
    "First of all, I should tell you why parsers are so beautifully expressed in a functional framework: a lot of grammars have an inherently recursive structure. Take as an example a structure of nested lists:\n",
    "\n",
    "```python\n",
    "[a,[b,c],d,[[e]]]\n",
    "```\n",
    "\n",
    "From such an example we can expect to see recursion playing a role in parsing. In BNF this looks like:\n",
    "\n",
    "```bash\n",
    "<expr>   ::= <list> | <symbol>\n",
    "<list>   ::= '[' <seq> ']'\n",
    "<seq>    ::= <expr> | <expr> ',' <seq>\n",
    "<symbol> ::= 'a-z' | <symbol>\n",
    "```\n",
    "\n",
    "Note: if you find this notation confusing, you may want to take a look at [this video](https://www.youtube.com/watch?v=dDtZLm7HIJs).\n",
    "\n",
    "Notice the definition of a `<list>` depends on `<seq>` depends on `<expr>` depends on `<list>`. Seen like this, even `<seq>` and `<symbol>` are recursive in the BNF; although in this case the (simple) recursion expresses the sequential nature of these grammars. In the case of sequences, we may replace the recursion with an (imperative) for-loop and be done with it. In almost every real word case however, we deal with more involved recursions like the nested list example. Functional parsers often have definitions that lie closer to the BNF notation shown above. Functional languages in which these parsers are implemented often have the features (either tail-call elimination or lazy evaluation) to handle these definitions without too much loss of performance.\n",
    "\n",
    "> Tail recursion in BNF\n",
    "> ---------------------\n",
    ">\n",
    "> Let's expand the definition of `<list>` by replacing `<seq>` with its definition (We'll use parentheses and ellipses in free but predictable manner).\n",
    "> \n",
    "> ```bash\n",
    "> <list> = '[' (<expr> | <expr> ',' <seq>) ']'\n",
    "> <list> = '[' ((<list> | <symbol>) | (<list> | <symbol>) ',' <seq>) ']'\n",
    "> ```\n",
    ">\n",
    "> We may now choose a path in this expression. A possible `<list>` looks like:\n",
    ">\n",
    "> ```bash\n",
    "> <list> =? '[' <list> ',' <seq> ']'\n",
    "> ```\n",
    ">\n",
    "> We see `<list>` reappearing in a position that is not at the tail-end of the BNF expression. Contrast this to `<symbol>`:\n",
    ">\n",
    "> ```bash\n",
    "> <symbol> = 'a-z' 'a-z' ... ('a-z' | <symbol>)\n",
    "> ```\n",
    "> \n",
    "> No matter how we expand the expression, the recursion is always at the end. In evaluating a tail-recursion, the recursion can always be converted to a (more efficient) loop.\n",
    "\n",
    "Because Python is neither lazy nor tail-recursive, we need to do a bit more work. We use a **trampoline** to effect tail recursion.\n",
    "    \n",
    "Functional parsers (or parser-combinators) are a method of writing and combining parsers. They allow you to build complex parsers from the ground up using a set of basic primitives. The structure is outlined in the beautiful Functional Pearl by Hutton and Meijer [@monadic-parsing].\n",
    "\n",
    "Since monads are not really a thing in Python, we'll have to somehow translate these concepts. In its most basic form, a parser is a function that takes a string and returns a parsed object together with the rest of the string. Graham Hutton puts it in a rhyme, which I changed slightly to suit our context:\n",
    "\n",
    "> A parser for things  \n",
    "> Is a function from strings  \n",
    "> To options of pairs  \n",
    "> Of things and strings  \n",
    "\n",
    "The optional part in our case means: may throw an exception instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional, Union, Callable, Any, TypeVar, Generic\n",
    "\n",
    "T = TypeVar(\"T\")\n",
    "Parser = Callable[[str], tuple[T, str]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Failures\n",
    "If the parser fails, a `Failure` is raised."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "class Failure(Exception):\n",
    "    def __init__(self, msg: str):\n",
    "        self.msg = msg\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.msg\n",
    "\n",
    "\n",
    "class EndOfInput(Failure):\n",
    "    def __init__(self):\n",
    "        super().__init__(\"End of input.\")\n",
    "\n",
    "    \n",
    "class Expected(Failure):\n",
    "    def __init__(self, inp: str, msg: str):\n",
    "        self.msg = msg\n",
    "        self.inp = inp\n",
    "        \n",
    "    def __str__(self):\n",
    "        return f\"{self.msg}, got: {self.inp}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with an example of a function that parses a positive integer. Here we use a regular expression to parse the integer itself. From this first parser we'll expand out to write something that can parse an arbitrarily nested list of integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def integer(inp: str) -> tuple[int, str]:\n",
    "    if m := re.match(\"-?[1-9][0-9]*\", inp):\n",
    "        result = int(m[0])\n",
    "        rest = inp[m.end(0):]\n",
    "        return (result, rest)\n",
    "    else:\n",
    "        raise Expected(inp, \"a number\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42, '')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "integer(\"42\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the second return value is the part of the input that is remaining after our parser is done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89, ', 20, 40')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "integer(\"89, 20, 40\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Expected: a number, got: hello\n"
     ]
    }
   ],
   "source": [
    "integer(\"hello\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now say we want to parse **two** integers. We need to be able to parse some whitespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def whitespace(inp: str) -> tuple[str, str]:\n",
    "    m = re.match(\"\\s+\", inp)\n",
    "    if not m:\n",
    "        raise Expected(inp, \"whitespace\")\n",
    "    return (m[0], inp[m.end(0):])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('    ', 'abcd')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whitespace(\"    abcd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Expected: whitespace, got: abcd\n"
     ]
    }
   ],
   "source": [
    "whitespace(\"abcd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In many cases whitespace is optional. We can write another parser that catches the exception for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optional(p: Parser[T]) -> Parser[Optional[T]]:\n",
    "    def optional_p(inp: str) -> tuple[Optional[T], str]:\n",
    "        try:\n",
    "            (x, inp) = p(inp)\n",
    "        except Failure:\n",
    "            return (None, inp)\n",
    "        return (x, inp)\n",
    "    return optional_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 'abcd')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optional(whitespace)(\"abcd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us try to parse a pair of integers now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def twice(p: Parser[T]) -> Parser[tuple[T, T]]:\n",
    "    def twiced(inp: str) -> tuple[tuple[T, T], str]:\n",
    "        (a, inp) = p(inp)\n",
    "        (_, inp) = whitespace(inp)\n",
    "        (b, inp) = p(inp)\n",
    "        return ((a, b), inp)\n",
    "    return twiced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 2), ' 3 4')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twice(integer)(\"1 2 3 4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could also go for a comma separated list of integers. First we need to parse a comma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def char(allowed: str) -> Parser[str]:\n",
    "    def char_p(inp: str) -> tuple[str, str]:\n",
    "        if not inp or inp[0] not in allowed:\n",
    "            raise Expected(inp, f\"one of \\\"{allowed}\\\"\")\n",
    "        return (inp[0], inp[1:])\n",
    "    return char_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('a', 'bbcaabd')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char(\"abc\")(\"abbcaabd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Expected: one of \"abc\", got: d\n"
     ]
    }
   ],
   "source": [
    "char(\"abc\")(\"d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(',', ' 20, 40')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comma = char(\",\")\n",
    "comma(\", 20, 40\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Expected: one of \",\", got: 89, 20, 40\n"
     ]
    }
   ],
   "source": [
    "comma(\"89, 20, 40\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will be convenient to have a function that parses a thing and then also consumes the whitespace after it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(p: Parser[T]) -> Parser[T]:\n",
    "    def tokenized(inp: str) -> tuple[T, str]:\n",
    "        (x, inp) = p(inp)\n",
    "        (_, inp) = optional(whitespace)(inp)\n",
    "        return (x, inp)\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the definition of `tokenize` no longer contains any raw string processing! Also, see how the whitespace is stripped from our input!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(',', '######')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comma = tokenize(char(\",\"))\n",
    "comma(\",     ######\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now want to parse a list of integers, separated by commas. We can try to do this recursively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "U = TypeVar(\"U\")\n",
    "\n",
    "def sep_by(p: Parser[T], sep: Parser[U]) -> Parser[list[T]]:\n",
    "    def sep_byed(inp: str) -> tuple[list[T], str]:\n",
    "        # parse an integer\n",
    "        (x, inp) = p(inp)\n",
    "        try:\n",
    "            # parse a comma\n",
    "            (_, _inp) = sep(inp)\n",
    "            # parse the rest of the list\n",
    "            (rest, inp) = sep_byed(_inp)\n",
    "        except Failure:\n",
    "            return ([x], inp)\n",
    "        return ([x] + rest, inp)\n",
    "    return sep_byed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1, 2, 3, 4], ', abcde')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sep_by(integer, comma)(\"1, 2, 3, 4, abcde\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This implementation is not so effecient, and because it uses recursion we run the risc of stack overflow. We can write the inner function in an imperative style to be more efficient here. Later on we will see that we can write recursive parsers safely, but even then, seeing that this is Python and not Haskell, it can be advantageous to rewrite some core parsers imperatively. The important bit is that the framework still stands: the outer world doesn't see your trash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sep_by(p: Parser[T], sep: Parser[U]) -> Parser[list[T]]:\n",
    "    def sep_byed(inp: str) -> tuple[list[T], str]:\n",
    "        result = []\n",
    "        inp_bc = inp\n",
    "        while True:\n",
    "            try:\n",
    "                (x, inp_bc) = p(inp)\n",
    "                result.append(x)\n",
    "                (_, inp) = sep(inp_bc)\n",
    "            except Failure:\n",
    "                return (result, inp_bc)\n",
    "    return sep_byed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1, 2, 3, 4], ', abcde')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sep_by(integer, comma)(\"1, 2, 3, 4, abcde\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Many and some\n",
    "\n",
    "`many` and `some` are bread and butter of parser combinators. An important fact to note here is that `many` will always succeed. Having nested `many` parsers may result in infinite loops."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def many(p: Parser[T]) -> Parser[list[T]]:\n",
    "    def manied(inp: str) -> tuple[list[T], str]:\n",
    "        result = []\n",
    "        while True:\n",
    "            try:\n",
    "                (x, inp) = p(inp)\n",
    "                result.append(x)\n",
    "            except Failure:\n",
    "                return (result, inp)\n",
    "    return manied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def some(p: Parser[T]) -> Parser[list[T]]:\n",
    "    def somed(inp: str) -> tuple[list[T], str]:\n",
    "        (x, inp) = p(inp)\n",
    "        (rest, inp) = many(p)(inp)\n",
    "        return ([x] + rest, inp)\n",
    "    return somed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, we can now write a parser for a list of integers, S-expression style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_of(p: Parser[T]) -> Parser[list[T]]:\n",
    "    def listed(inp: str) -> tuple[list[T], str]:\n",
    "        (_, inp) = tokenize(char(\"(\"))(inp)\n",
    "        (x, inp) = many(p)(inp)\n",
    "        (_, inp) = tokenize(char(\")\"))(inp)\n",
    "        return (x, inp)\n",
    "    return listed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1, 2, 3], '')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of(tokenize(integer))(\"(1 2 3)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choices\n",
    "\n",
    "Another common pattern is when we have several options to parse. For the `choice` parser we need a new type of `Failure`, namely one that outlines the different expectations and why they all failed. The `choice` parser tries each parser in the order they were given; the first parser to succeed gets the go-ahead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChoiceFailure(Expected):\n",
    "    def __init__(self, inp, failures):\n",
    "        super().__init__(inp, \"\")\n",
    "        self.failures = failures\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"All options failed:\\n\" + \"\\n\".join(\n",
    "            \"    | \" + f.msg for f in self.failures) + \\\n",
    "            f\"\\ngot: {self.inp}\"\n",
    "\n",
    "def choice(*ps: Parser[T]) -> Parser[T]:\n",
    "    def choiced(inp: str) -> tuple[T, str]:\n",
    "        failures = []\n",
    "        for p in ps:\n",
    "            try:\n",
    "                (x, inp) = p(inp)\n",
    "            except Failure as f:\n",
    "                failures.append(f)\n",
    "                continue\n",
    "            else:\n",
    "                return (x, inp)\n",
    "        raise ChoiceFailure(inp, failures)\n",
    "    return choiced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['1', '2', 'a', 'b', '3'], '#$*&(*&@')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "many(choice(char(\"abc\"), char(\"123\")))(\"12ab3#$*&(*&@\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ChoiceFailure: All options failed:\n",
      "    | one of \"abc\"\n",
      "    | one of \"123\"\n",
      "    | whitespace\n",
      "got: #&*(&@\n"
     ]
    }
   ],
   "source": [
    "some(choice(char(\"abc\"), char(\"123\"), whitespace))(\"#&*(&@\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nested structures\n",
    "\n",
    "We are now ready to parse a nested list structure. Note that the only reason why we put this parser in a function explicitely is to allow the recursion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nested_list(p: Parser[T]) -> Parser[Any]:\n",
    "    def nested_listed(inp: str) -> tuple[Any, str]:\n",
    "        return choice(p, list_of(nested_list(p)))(inp)\n",
    "    return nested_listed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1, 2, [3, 4], 5, [[], [6]]], '')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nested_list(tokenize(integer))(\"(1 2 (3 4  )5 (() (6)))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This concludes the basic introduction to parser combinators. What is left is finding ways of writing down parsers in a nicer way. First we'll have to deal with the pesky problem of recursion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequencing\n",
    "We have seen several instances where we had to sequence `(x, inp) = parse(inp)`. It would be nice if we could combine parsers in a smarter way, and have them plug together. In other words: we can make these parsers more composable. Suppose we want a function `sequence(*ps)` that parses each argument in order, and returns the result of the last parser. An imperative solution looks as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence(*ps: Parser[Any]) -> Parser[Any]:\n",
    "    def sequenced(inp: str) -> tuple[Any, str]:\n",
    "        for p in ps:\n",
    "            (x, inp) = p(inp)\n",
    "        return (x, inp)\n",
    "    return sequenced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every intermediate result is thrown away. Now suppose we have two parsers, we need the result of the first one, but only if the second one succeeds. We saw this case before when we were parsing lists. We make things a bit easier by omitting commas, so we're parsing `(1 2 3)` now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_of(p: Parser[T]) -> Parser[list[T]]:\n",
    "    return sequence(char(\"(\"), closed_by(many(p), char(\")\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How would we implement `closed_by()`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closed_by(p1: Parser[T], p2: Parser[U]) -> Parser[T]:\n",
    "    def closed_byed(inp: str) -> tuple[T, str]:\n",
    "        (x, inp) = p1(inp)\n",
    "        (_, inp) = p2(inp)\n",
    "        return (x, inp)\n",
    "    return closed_byed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value(x: T) -> Parser[T]:\n",
    "    def valued(inp: str) -> tuple[T, str]:\n",
    "        return (x, inp)\n",
    "    return valued\n",
    "\n",
    "def closed_by(p1: Parser[T], p2: Parser[U]) -> Parser[T]:\n",
    "    # return bind(p1, lambda x: bind(p2, lambda _: value(x)))\n",
    "    return p1 >> (lambda x: p2 >> (lambda _: value(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_recur(p: Parser[Any], *ps: Parser[Any]) -> Parser[Any]:\n",
    "    def sequenced(inp: str) -> tuple[Any, str]:\n",
    "        (_, inp) = p(inp)\n",
    "        return sequence_recur(*ps)(inp)\n",
    "\n",
    "    if ps:\n",
    "        return sequenced\n",
    "    else:\n",
    "        return p\n",
    "    \n",
    "\n",
    "def bind(p: Parser[T], f: Callable[(T,), Parser[U]]) -> Parser[U]:\n",
    "    def bound(inp: str) -> tuple[U, str]:\n",
    "        (x, inp) = p(inp)\n",
    "        return f(x)(inp)\n",
    "    return bound\n",
    "\n",
    "\n",
    "def sequence_bind(p: Parser[Any], *ps: Parser[Any]) -> Parser[Any]:\n",
    "    if ps:\n",
    "        return bind(p, lambda _: sequence_bind(*ps))\n",
    "    else:\n",
    "        return p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trampolines\n",
    "Trampolines can be a bit tricky to understand, so we first explain them using the example of a `factorial` function. The factorial of $n$, noted $n! := n (n - 1)!$, also $0! := 1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factorial(n):\n",
    "    if n == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return n * factorial(n - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3628800"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "factorial(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RecursionError: maximum recursion depth exceeded\n"
     ]
    }
   ],
   "source": [
    "factorial(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we elude this recursion? We could write a for-loop, but let's say we want still want to use write a recursion. After all, when we're writing parsers recursions can become inevitable: see for instance the nested list example. First what we need to change is to make the function **tail-recursive**. This is done by adding an accumulator argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def factorial(n, acc=1):\n",
    "    if n == 0:\n",
    "        return acc\n",
    "    else:\n",
    "        return factorial(n-1, acc*n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference is that we return the direct result of the recursive function call. In the previous version we still had to multiply the result of the recursion by `n`. If the return value of a function is the direct result of another (recursive) function call, we may call the function **tail-recursive**. Written in this way, we can prevent the call from allocating another stack frame.\n",
    "\n",
    "What we do is **delaying the call**.\n",
    "\n",
    "We store the function call in an object of class `Trampoline`. We may call the `compute()` method on this class to start a loop. This loop keeps evaluating successive calls, until the result is something else than a `Trampoline` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trampoline:\n",
    "    def __init__(self, func, *args, **kwargs):\n",
    "        self.func = func\n",
    "        self.args = args\n",
    "        self.kwargs = kwargs\n",
    "        \n",
    "    def compute(self):\n",
    "        cont = self\n",
    "        while True:\n",
    "            cont = cont.func(*cont.args, **cont.kwargs)\n",
    "            if not isinstance(cont, Trampoline):\n",
    "                return cont\n",
    "\n",
    "def factorial(n, acc=1):\n",
    "    if n == 0:\n",
    "        return acc\n",
    "    else:\n",
    "        return Trampoline(factorial, n-1, acc*n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35659.45427452078"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import log10\n",
    "log10(factorial(10000).compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make this example a bit more beautiful by providing a decorator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import (wraps, partial)\n",
    "\n",
    "def trampoline(f):\n",
    "    return wraps(f)(partial(Trampoline, f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can keep our old definition!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "@trampoline\n",
    "def factorial(n, acc=1):\n",
    "    if n == 0:\n",
    "        return acc\n",
    "    else:\n",
    "        return factorial(n-1, acc*n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35659.45427452078"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log10(factorial(10000).compute())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The full parser\n",
    "These parsers had us chain several `(x, inp) = some_parser(inp)` together. It would be cool if we had a better syntax to write that. To do this however, we need to wrap our parser functions in a class. Then the question is also: how do we propagate the return value `x` through this chain? In Haskell this problem is solved with monads. We can try to do the same in Python, especially now that we have trampolines.\n",
    "\n",
    "There will be two more additions to the scheme outlined above: the **cursor** and the **auxiliary state** object.\n",
    "\n",
    "### Cursor\n",
    "When parsing larger files it can be inefficient to parse a text character by character. Often, we need to pass a certain amount of text to a secondary function that then converts the string into a value for us. Instead of working directly with strings we can use a `Cursor` class.\n",
    "\n",
    "In normal parsing mode, we need only to know the position of the cursor within the text; however, on many occasion it is useful to have a cursor object that spans a selection of text being parsed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Cursor:\n",
    "    data: bytes\n",
    "    begin: int\n",
    "    end: int\n",
    "    encoding: str = \"utf-8\"\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"Length of selection.\"\"\"\n",
    "        return self.end - self.begin\n",
    "    \n",
    "    def __bool__(self):\n",
    "        \"\"\"Returns `True` if there is more input to parse, `False` otherwise.\"\"\"\n",
    "        return self.end < len(self.data)\n",
    "    \n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the full definition, see the corresponding API documentation.\n",
    "\n",
    "### Auxiliary state\n",
    "The same way we pass the cursor state through all the parser calls, we can track auxiliary state. The complete function signature of a parser then looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def some_parser(cursor: Cursor, aux: Any) -> tuple[T, Cursor, Any]:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the current set of parsers, this state is used as a stack. The stack is initialized with the empty list, then values can be pushed and popped using the `push` and `pop` parsers. The `pop` parser takes an optional `transfer` argument that maps the content of the popped value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from byteparsing import sequence, push, pop\n",
    "\n",
    "sequence(push(42), pop()).parse(b\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HELLO'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from byteparsing import many_char_0, flush_decode, char, ascii_alpha, flush\n",
    "\n",
    "sequence(char(\"(\"), flush(),\n",
    "         many_char_0(ascii_alpha),\n",
    "         flush_decode() >> push,\n",
    "         char(\")\"),\n",
    "         pop(str.upper)).parse(b\"(hello)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hide trace backs\n",
    "For the purpose of this notebook it was better to hide tracebacks on exceptions. Run this cell first, then the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "ipython = get_ipython()\n",
    "\n",
    "def exception_handler(exception_type, exception, traceback):\n",
    "    print(\"%s: %s\" % (exception_type.__name__, exception), file=sys.stderr)\n",
    "\n",
    "ipython._showtraceback = exception_handler"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
